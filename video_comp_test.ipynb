{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "id": "XIdrnEorPTWj"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "zPrZPbupt260"
      },
      "outputs": [],
      "source": [
        "# #--------------------------intra frame prediction-----------------------------------#\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# def intra_frame_prediction(current_frame):\n",
        "#     # Convert the frame to grayscale\n",
        "#     gray_frame = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#     # Get the frame dimensions\n",
        "#     height, width = gray_frame.shape\n",
        "\n",
        "#     # Create an empty array for the predicted frame\n",
        "#     predicted_frame = np.zeros_like(gray_frame)\n",
        "\n",
        "#     # Iterate over blocks (e.g., 4x4 blocks) and perform spatial prediction\n",
        "#     block_size = 4\n",
        "#     for y in range(0, height, block_size):\n",
        "#         for x in range(0, width, block_size):\n",
        "#             # Get the current block\n",
        "#             current_block = gray_frame[y:y+block_size, x:x+block_size]\n",
        "\n",
        "#             # Predict the block based on neighboring pixels (simple averaging)\n",
        "#             prediction = np.mean(current_block)\n",
        "\n",
        "#             # Fill the predicted block in the predicted frame\n",
        "#             predicted_frame[y:y+block_size, x:x+block_size] = prediction\n",
        "\n",
        "#     return predicted_frame\n",
        "\n",
        "# # Example usage\n",
        "# current_frame = cv2.imread(\"/content/frames/frame_0000.jpg\")\n",
        "\n",
        "# predicted_frame = intra_frame_prediction(current_frame)\n",
        "\n",
        "# # Display the original and predicted frames for visual comparison in Colab\n",
        "# cv2_imshow(current_frame)\n",
        "# cv2_imshow(predicted_frame)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "id": "9TCZwmNPuvqM"
      },
      "outputs": [],
      "source": [
        "# #---------------------Inter frame prediction-----------------------------------------#\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# def inter_frame_prediction(prev_frame, current_frame, next_frame):\n",
        "#     # Convert frames to grayscale\n",
        "#     prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "#     current_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
        "#     next_gray = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#     # Compute motion vectors between frames (previous to current and current to next)\n",
        "#     flow_prev_current = cv2.calcOpticalFlowFarneback(prev_gray, current_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "#     flow_current_next = cv2.calcOpticalFlowFarneback(current_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "#     # Apply motion vectors to predict the current frame\n",
        "#     predicted_current_frame = cv2.remap(current_frame, flow_prev_current, None, cv2.INTER_LINEAR)\n",
        "#     predicted_next_frame = cv2.remap(current_frame, flow_current_next, None, cv2.INTER_LINEAR)\n",
        "\n",
        "#     # Interpolate between the two predictions to get the final predicted frame\n",
        "#     alpha = 0.5  # Interpolation factor\n",
        "#     final_predicted_frame = cv2.addWeighted(predicted_current_frame, alpha, predicted_next_frame, 1 - alpha, 0)\n",
        "\n",
        "#     return final_predicted_frame\n",
        "\n",
        "# # Example usage\n",
        "# prev_frame = cv2.imread(\"/content/frames/frame_0000.jpg\")\n",
        "# current_frame = cv2.imread(\"/content/frames/frame_0002.jpg\")\n",
        "# next_frame = cv2.imread(\"/content/frames/frame_0005.jpg\")\n",
        "\n",
        "# predicted_frame = inter_frame_prediction(prev_frame, current_frame, next_frame)\n",
        "\n",
        "# # Display the original and predicted frames for visual comparison\n",
        "# cv2_imshow( current_frame)\n",
        "# cv2_imshow( predicted_frame)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "id": "qqzqFwRKNJQb"
      },
      "outputs": [],
      "source": [
        "# #---------------------------motion vector prediction---------------------------------#\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# def motion_vector_prediction(prev_frame, current_frame):\n",
        "#     # Convert frames to grayscale\n",
        "#     prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "#     current_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#     # Calculate dense optical flow using Farneback method\n",
        "#     flow = cv2.calcOpticalFlowFarneback(prev_gray, current_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "#     # Get the motion vectors for each pixel\n",
        "#     motion_vectors = flow.reshape(-1, 2)\n",
        "\n",
        "#     return motion_vectors\n",
        "\n",
        "# # Example usage\n",
        "# prev_frame = cv2.imread(\"/content/frames/frame_0000.jpg\")\n",
        "# current_frame = cv2.imread(\"/content/frames/frame_0200.jpg\")\n",
        "\n",
        "# motion_vectors = motion_vector_prediction(prev_frame, current_frame)\n",
        "\n",
        "# # Display the original and motion vector prediction for visual comparison\n",
        "\n",
        "# cv2_imshow( current_frame)\n",
        "\n",
        "# # Draw motion vectors on the current frame for visualization\n",
        "# for vector in motion_vectors:\n",
        "#     start_point = tuple(vector.astype(int))\n",
        "#     end_point = tuple((vector + [10, 10]).astype(int))  # Adjust the length of the vector for visualization\n",
        "#     cv2.arrowedLine(current_frame, start_point, end_point, (0, 255, 0), 1)\n",
        "\n",
        "# cv2_imshow( current_frame)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "id": "jhTF6zqLSXnR"
      },
      "outputs": [],
      "source": [
        "#------------------spliting as frames--------------------------#\n",
        "\n",
        "def split_video_frames(input_video, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Define the FFmpeg command to extract frames at 1 frame per second\n",
        "    ffmpeg_command = [\n",
        "        'ffmpeg',\n",
        "        '-i', input_video,\n",
        "        '-vf', 'fps=10',\n",
        "        os.path.join(output_folder, 'frame_%4d.jpg')\n",
        "    ]\n",
        "\n",
        "    # Execute the FFmpeg command\n",
        "    subprocess.run(ffmpeg_command)\n",
        "\n",
        "# Example usage\n",
        "input_video = \"/content/mov_2.mov\"\n",
        "output_folder = \"/content/frames_jpg_8\"\n",
        "\n",
        "split_video_frames(input_video, output_folder)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "DryDk6Wicypk"
      },
      "outputs": [],
      "source": [
        "# Code to Perform Block Matching\n",
        "debug = True\n",
        "\n",
        "def YCrCb2BGR(image):\n",
        "    \"\"\"\n",
        "    Converts numpy image into from YCrCb to BGR color space\n",
        "    \"\"\"\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
        "\n",
        "def BGR2YCrCb(image):\n",
        "    \"\"\"\n",
        "    Converts numpy image into from BGR to YCrCb color space\n",
        "    \"\"\"\n",
        "    return cv2.cvtColor(image, cv2.COLOR_YCrCb2BGR)\n",
        "\n",
        "def segmentImage(anchor, blockSize=16):\n",
        "    \"\"\"\n",
        "    Determines how many macroblocks an image is composed of\n",
        "    :param anchor: I-Frame\n",
        "    :param blockSize: Size of macroblocks in pixels\n",
        "    :return: number of rows and columns of macroblocks within\n",
        "    \"\"\"\n",
        "    h, w = anchor.shape\n",
        "    hSegments = int(h / blockSize)\n",
        "    wSegments = int(w / blockSize)\n",
        "    totBlocks = int(hSegments * wSegments)\n",
        "\n",
        "    #if debug:\n",
        "    #    print(f\"Height: {h}, Width: {w}\")\n",
        "    #    print(f\"Segments: Height: {hSegments}, Width: {wSegments}\")\n",
        "    #    print(f\"Total Blocks: {totBlocks}\")\n",
        "\n",
        "    return hSegments, wSegments\n",
        "\n",
        "def getCenter(x, y, blockSize):\n",
        "    \"\"\"\n",
        "    Determines center of a block with x, y as top left corner coordinates and blockSize as blockSize\n",
        "    :return: x, y coordinates of center of a block\n",
        "    \"\"\"\n",
        "    return (int(x + blockSize/2), int(y + blockSize/2))\n",
        "\n",
        "def getAnchorSearchArea(x, y, anchor, blockSize, searchArea):\n",
        "    \"\"\"\n",
        "    Returns image of anchor search area\n",
        "    :param x, y: top left coordinate of macroblock in Current Frame\n",
        "    :param anchor: I-Frame\n",
        "    :param blockSize: size of block in pixels\n",
        "    :param searchArea: size of search area in pixels\n",
        "    :return: Image of anchor search area\n",
        "    \"\"\"\n",
        "    h, w = anchor.shape\n",
        "    cx, cy = getCenter(x, y, blockSize)\n",
        "\n",
        "    sx = max(0, cx-int(blockSize/2)-searchArea) # ensure search area is in bounds\n",
        "    sy = max(0, cy-int(blockSize/2)-searchArea) # and get top left corner of search area\n",
        "\n",
        "    # slice anchor frame within bounds to produce anchor search area\n",
        "    anchorSearch = anchor[sy:min(sy+searchArea*2+blockSize, h), sx:min(sx+searchArea*2+blockSize, w)]\n",
        "\n",
        "    return anchorSearch\n",
        "\n",
        "def getBlockZone(p, aSearch, tBlock, blockSize):\n",
        "    \"\"\"\n",
        "    Retrieves the block searched in the anchor search area to be compared with the macroblock tBlock in the current frame\n",
        "    :param p: x,y coordinates of macroblock center from current frame\n",
        "    :param aSearch: anchor search area image\n",
        "    :param tBlock: macroblock from current frame\n",
        "    :param blockSize: size of macroblock in pixels\n",
        "    :return: macroblock from anchor\n",
        "    \"\"\"\n",
        "    px, py = p # coordinates of macroblock center\n",
        "    px, py = px-int(blockSize/2), py-int(blockSize/2) # get top left corner of macroblock\n",
        "    px, py = max(0,px), max(0,py) # ensure macroblock is within bounds\n",
        "\n",
        "    aBlock = aSearch[py:py+blockSize, px:px+blockSize] # retrive macroblock from anchor search area\n",
        "\n",
        "\n",
        "    try:\n",
        "        assert aBlock.shape == tBlock.shape # must be same shape\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(f\"ERROR - ABLOCK SHAPE: {aBlock.shape} != TBLOCK SHAPE: {tBlock.shape}\")\n",
        "\n",
        "    return aBlock\n",
        "\n",
        "def getMAD(tBlock, aBlock):\n",
        "    \"\"\"\n",
        "    Returns Mean Absolute Difference between current frame macroblock (tBlock) and anchor frame macroblock (aBlock)\n",
        "    \"\"\"\n",
        "    return np.sum(np.abs(np.subtract(tBlock, aBlock)))/(tBlock.shape[0]*tBlock.shape[1])\n",
        "\n",
        "def getBestMatch(tBlock, aSearch, blockSize): #3 Step Search\n",
        "    \"\"\"\n",
        "    Implemented 3 Step Search. Read about it here: https://en.wikipedia.org/wiki/Block-matching_algorithm#Three_Step_Search\n",
        "    :param tBlock: macroblock from current frame\n",
        "    :param aSearch: anchor search area\n",
        "    :param blockSize: size of macroblock in pixels\n",
        "    :return: macroblock from anchor search area with least MAD\n",
        "    \"\"\"\n",
        "    step = 4\n",
        "    ah, aw = aSearch.shape\n",
        "    acy, acx = int(ah/2), int(aw/2) # get center of anchor search area\n",
        "\n",
        "    minMAD = float(\"+inf\")\n",
        "    minP = None\n",
        "\n",
        "    while step >= 1:\n",
        "        p1 = (acx, acy)\n",
        "        p2 = (acx+step, acy)\n",
        "        p3 = (acx, acy+step)\n",
        "        p4 = (acx+step, acy+step)\n",
        "        p5 = (acx-step, acy)\n",
        "        p6 = (acx, acy-step)\n",
        "        p7 = (acx-step, acy-step)\n",
        "        p8 = (acx+step, acy-step)\n",
        "        p9 = (acx-step, acy+step)\n",
        "        pointList = [p1,p2,p3,p4,p5,p6,p7,p8,p9] # retrieve 9 search points\n",
        "\n",
        "        for p in range(len(pointList)):\n",
        "            aBlock = getBlockZone(pointList[p], aSearch, tBlock, blockSize) # get anchor macroblock\n",
        "            MAD = getMAD(tBlock, aBlock) # determine MAD\n",
        "            if MAD < minMAD: # store point with minimum mAD\n",
        "                minMAD = MAD\n",
        "                minP = pointList[p]\n",
        "\n",
        "        step = int(step/2)\n",
        "\n",
        "    px, py = minP # center of anchor block with minimum MAD\n",
        "    px, py = px - int(blockSize / 2), py - int(blockSize / 2) # get top left corner of minP\n",
        "    px, py = max(0, px), max(0, py) # ensure minP is within bounds\n",
        "    matchBlock = aSearch[py:py + blockSize, px:px + blockSize] # retrieve best macroblock from anchor search area\n",
        "\n",
        "    return matchBlock\n",
        "\n",
        "\n",
        "\n",
        "def blockSearchBody(anchor, target, blockSize, searchArea=7):\n",
        "    \"\"\"\n",
        "    Facilitates the creation of a predicted frame based on the anchor and target frame\n",
        "    :param anchor: I-Frame\n",
        "    :param target: Current Frame to create a P-Frame from\n",
        "    :param blockSize: size of macroBlock in pixels\n",
        "    :param searchArea: size of searchArea extended from blockSize\n",
        "    :return: predicted frame\n",
        "    \"\"\"\n",
        "    h, w = anchor.shape\n",
        "    hSegments, wSegments = segmentImage(anchor, blockSize)\n",
        "\n",
        "\n",
        "    predicted = np.ones((h, w))*255\n",
        "    bcount = 0\n",
        "    for y in range(0, int(hSegments*blockSize), blockSize):\n",
        "        for x in range(0, int(wSegments*blockSize), blockSize):\n",
        "            bcount+=1\n",
        "            targetBlock = target[y:y+blockSize, x:x+blockSize] #get current macroblock\n",
        "\n",
        "            anchorSearchArea = getAnchorSearchArea(x, y, anchor, blockSize, searchArea) #get anchor search area\n",
        "\n",
        "            #print(\"AnchorSearchArea: \", anchorSearchArea.shape)\n",
        "\n",
        "            anchorBlock = getBestMatch(targetBlock, anchorSearchArea, blockSize) #get best anchor macroblock\n",
        "            predicted[y:y+blockSize, x:x+blockSize] = anchorBlock #add anchor block to predicted frame\n",
        "\n",
        "            #cv2.imwrite(\"OUTPUT/predictedtestFrame.png\", predicted)\n",
        "            #print(f\"ITERATION {bcount}\")\n",
        "\n",
        "    #cv2.imwrite(\"OUTPUT/predictedtestFrame.png\", predicted)\n",
        "\n",
        "    #time.sleep(10)\n",
        "\n",
        "    assert bcount == int(hSegments*wSegments) #check all macroblocks are accounted for\n",
        "\n",
        "    return predicted\n",
        "\n",
        "def getResidual(target, predicted):\n",
        "    \"\"\"Create residual frame from target frame - predicted frame\"\"\"\n",
        "    return np.subtract(target, predicted)\n",
        "\n",
        "def getReconstructTarget(residual, predicted):\n",
        "    \"\"\"Reconstruct target frame from residual frame plus predicted frame\"\"\"\n",
        "    return np.add(residual, predicted)\n",
        "\n",
        "def showImages(*kwargs): #shows images\n",
        "    for k in range(len(kwargs)):\n",
        "        cv2.imshow(f\"Image: {k}\", k)\n",
        "        cv2.waitKey(-1)\n",
        "\n",
        "def getResidualMetric(residualFrame):\n",
        "    \"\"\"Calculate residual metric from average of sum of absolute residual values in residual frame\"\"\"\n",
        "    return np.sum(np.abs(residualFrame))/(residualFrame.shape[0]*residualFrame.shape[1])\n",
        "\n",
        "def preprocess(anchor, target, blockSize):\n",
        "\n",
        "    if isinstance(anchor, str) and isinstance(target, str):\n",
        "        anchorFrame = BGR2YCrCb(cv2.imread(anchor))[:, :, 0] # get luma component\n",
        "        targetFrame = BGR2YCrCb(cv2.imread(target))[:, :, 0] # get luma component\n",
        "\n",
        "    elif isinstance(anchor, np.ndarray) and isinstance(target, np.ndarray):\n",
        "        anchorFrame = BGR2YCrCb(anchor)[:, :, 0] # get luma component\n",
        "        targetFrame = BGR2YCrCb(target)[:, :, 0] # get luma component\n",
        "\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "    #resize frame to fit segmentation\n",
        "    hSegments, wSegments = segmentImage(anchorFrame, blockSize)\n",
        "    anchorFrame = cv2.resize(anchorFrame, (int(wSegments*blockSize), int(hSegments*blockSize)))\n",
        "    targetFrame = cv2.resize(targetFrame, (int(wSegments*blockSize), int(hSegments*blockSize)))\n",
        "\n",
        "    #if debug:\n",
        "        #print(f\"A SIZE: {anchorFrame.shape}\")\n",
        "        #print(f\"T SIZE: {targetFrame.shape}\")\n",
        "\n",
        "\n",
        "    return (anchorFrame, targetFrame)\n",
        "\n",
        "# def main(anchorFrame, targetFrame, outfile=\"OUTPUT\", saveOutput=True, blockSize = 16):\n",
        "#     \"\"\"\n",
        "#     Calculate residual frame and metric along with other artifacts\n",
        "#     :param anchor: file path of I-Frame or I-Frame\n",
        "#     :param target: file path of Current Frame or Current Frame\n",
        "#     :return: residual metric\n",
        "#     \"\"\"\n",
        "#     anchorFrame, targetFrame = preprocess(anchorFrame, targetFrame, blockSize) #processes frame or filepath to frame\n",
        "\n",
        "#     predictedFrame = blockSearchBody(anchorFrame, targetFrame, blockSize)\n",
        "#     residualFrame = getResidual(targetFrame, predictedFrame)\n",
        "#     naiveResidualFrame = getResidual(anchorFrame, targetFrame)\n",
        "#     reconstructTargetFrame = getReconstructTarget(residualFrame, predictedFrame)\n",
        "#     #showImages(targetFrame, predictedFrame, residualFrame)\n",
        "\n",
        "#     residualMetric = getResidualMetric(residualFrame)\n",
        "#     naiveResidualMetric = getResidualMetric(naiveResidualFrame)\n",
        "\n",
        "#     rmText = f\"Residual Metric: {residualMetric:.2f}\"\n",
        "#     nrmText = f\"Naive Residual Metric: {naiveResidualMetric:.2f}\"\n",
        "\n",
        "#     isdir = os.path.isdir(outfile)\n",
        "#     if not isdir:\n",
        "#         os.mkdir(outfile)\n",
        "\n",
        "#     if saveOutput:\n",
        "#         cv2.imwrite(f\"{outfile}/targetFrame.png\", targetFrame)\n",
        "#         cv2.imwrite(f\"{outfile}/predictedFrame.png\", predictedFrame)\n",
        "#         cv2.imwrite(f\"{outfile}/residualFrame.png\", residualFrame)\n",
        "#         cv2.imwrite(f\"{outfile}/reconstructTargetFrame.png\", reconstructTargetFrame)\n",
        "#         cv2.imwrite(f\"{outfile}/naiveResidualFrame.png\", naiveResidualFrame)\n",
        "#         resultsFile = open(f\"{outfile}/results.txt\", \"w\"); resultsFile.write(f\"{rmText}\\n{nrmText}\\n\"); resultsFile.close()\n",
        "\n",
        "#     print(rmText)\n",
        "#     print(nrmText)\n",
        "\n",
        "#     return residualMetric, residualFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "KJVZ4FbjEZFm"
      },
      "outputs": [],
      "source": [
        "\n",
        "def read_jpg_images(folder_path):\n",
        "    # List all files in the folder\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.jpg')]\n",
        "\n",
        "    # Sort the image files based on their names\n",
        "    image_files.sort()\n",
        "\n",
        "    # Read each JPG image and store them in a list\n",
        "    images = []\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        img = cv2.imread(image_path)\n",
        "        images.append(img)\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "def plot_images(image_list):\n",
        "    for i, img in enumerate(image_list):\n",
        "        cv2_imshow( img)\n",
        "\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "jpg_folder_path ='/content/frames_jpg_8'\n",
        "\n",
        "images = read_jpg_images(jpg_folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "W2vv_DwrU9fr"
      },
      "outputs": [],
      "source": [
        "#-------------------------------PSNR------------------------------------------------#\n",
        "'''\n",
        "PSNR>30: Compressed image is with high quality\n",
        "20<PSNR<30: Compressed image is in medium quality\n",
        "PSNR<20: Compresses image is in low quality\n",
        "\n",
        "'''\n",
        "\n",
        "def psnr(original, compressed):\n",
        "    # Ensure both images have the same shape\n",
        "    assert original.shape == compressed.shape, \"Images must have the same dimensions\"\n",
        "\n",
        "    # Compute Mean Squared Error (MSE)\n",
        "    mse = np.mean((original - compressed) ** 2)\n",
        "\n",
        "    # Compute Peak Signal Power (PSP)\n",
        "    psp = np.max(original) ** 2\n",
        "\n",
        "    # Compute PSNR\n",
        "    psnr_value = 10 * np.log10(psp / mse)\n",
        "\n",
        "    return psnr_value\n",
        "# Assuming 'original_image' and 'compressed_image' are NumPy arrays\n",
        "# psnr_value = psnr(gray_image, inverse_dct_result)\n",
        "# print(f\"PSNR: {psnr_value} dB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "XTs5nttOa6Uq"
      },
      "outputs": [],
      "source": [
        "def split_into_blocks(matrix, block_size=8):\n",
        "    rows, cols = matrix.shape\n",
        "    block_matrices = []\n",
        "\n",
        "    for row in range(0, rows, block_size):\n",
        "        for col in range(0, cols, block_size):\n",
        "            block = matrix[row:row+block_size, col:col+block_size]\n",
        "            block_matrices.append(block)\n",
        "\n",
        "    return block_matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "0PzBwgRtD6jF"
      },
      "outputs": [],
      "source": [
        "def quantize(block, quality):\n",
        "    # Quality levels for JPEG (Q50, Q70, Q90)\n",
        "    quality_factors = np.array([\n",
        "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
        "        [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "        [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "        [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "        [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "        [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "        [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "        [72, 92, 95, 98, 112, 100, 103, 99]\n",
        "    ])\n",
        "\n",
        "    if quality < 40:\n",
        "        scale = 40 / quality\n",
        "        quality_level = \"Low Quality\"\n",
        "    elif 40 <= quality <= 70:\n",
        "        scale = 2 - quality / 70\n",
        "        quality_level = \"Medium Quality\"\n",
        "    else:\n",
        "        scale = 100 / quality\n",
        "        quality_level = \"High Quality\"\n",
        "\n",
        "    quantized_block = np.round(block / ((quality_factors+100)* scale))\n",
        "\n",
        "    return quantized_block, quality_level\n",
        "\n",
        "def dequantize(quantized_block, quality):\n",
        "    # Quality levels for JPEG (Q50, Q70, Q90)\n",
        "    quality_factors = np.array([\n",
        "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
        "        [12, 12, 14, 19, 26, 58, 60, 55],\n",
        "        [14, 13, 16, 24, 40, 57, 69, 56],\n",
        "        [14, 17, 22, 29, 51, 87, 80, 62],\n",
        "        [18, 22, 37, 56, 68, 109, 103, 77],\n",
        "        [24, 35, 55, 64, 81, 104, 113, 92],\n",
        "        [49, 64, 78, 87, 103, 121, 120, 101],\n",
        "        [72, 92, 95, 98, 112, 100, 103, 99]\n",
        "    ])\n",
        "\n",
        "    if quality < 40:\n",
        "        scale = 40 / quality\n",
        "    elif 40 <= quality <= 70:\n",
        "        scale = 2 - quality / 70\n",
        "    else:\n",
        "        scale = 100 / quality\n",
        "\n",
        "    return quantized_block * ((quality_factors+100) * scale)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "EAEz96vS4i2f"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "from collections import defaultdict\n",
        "\n",
        "def calculate_frequencies(arr):\n",
        "    frequencies = defaultdict(int)\n",
        "    for row in arr:\n",
        "        for col in row:\n",
        "            for value in col:\n",
        "                frequencies[value] += 1\n",
        "    return frequencies\n",
        "\n",
        "def build_huffman_tree(frequencies):\n",
        "    heap = [[weight, [value, \"\"]] for value, weight in frequencies.items()]\n",
        "    heapq.heapify(heap)\n",
        "    while len(heap) > 1:\n",
        "        lo = heapq.heappop(heap)\n",
        "        hi = heapq.heappop(heap)\n",
        "        for pair in lo[1:]:\n",
        "            pair[1] = '0' + pair[1]\n",
        "        for pair in hi[1:]:\n",
        "            pair[1] = '1' + pair[1]\n",
        "        heapq.heappush(heap, [lo[0] + hi[0]] + lo[1:] + hi[1:])\n",
        "    return heap[0][1:]\n",
        "\n",
        "def generate_huffman_code(tree):\n",
        "    huffman_code = {}\n",
        "    for value, code in tree:\n",
        "        huffman_code[value] = code\n",
        "    return huffman_code\n",
        "\n",
        "def huffman_encode(arr, huffman_code):\n",
        "    encoded_arr = [[[huffman_code[value] for value in col] for col in row] for row in arr]\n",
        "    return encoded_arr\n",
        "\n",
        "def huffman_decode(encoded_arr, huffman_code):\n",
        "    decoding_dict = {code: value for value, code in huffman_code.items()}\n",
        "    decoded_arr = [[[decoding_dict[code] for code in col] for col in row] for row in encoded_arr]\n",
        "    return decoded_arr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "hG2sSOT258JT"
      },
      "outputs": [],
      "source": [
        "def calculate_total_bits(encoded_arr):\n",
        "    total_bits = 0\n",
        "    for row in encoded_arr:\n",
        "        for col in row:\n",
        "            for code in col:\n",
        "                total_bits += len(code)\n",
        "    return total_bits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "9fN_CTU99cF5"
      },
      "outputs": [],
      "source": [
        "def write_encoded_data_to_file(encoded_arr, output_file_path):\n",
        "    with open(output_file_path, 'w') as file:\n",
        "        for row in encoded_arr:\n",
        "            for col in row:\n",
        "                for code in col:\n",
        "                    file.write(code)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "id": "nf_h57L1s2a0"
      },
      "outputs": [],
      "source": [
        "def write_list_to_bin(data_list, output_path):\n",
        "    # Open the binary file in write mode\n",
        "    with open(output_path, 'wb') as bin_file:\n",
        "        # Serialize and write the list to the binary file\n",
        "        pickle.dump(data_list, bin_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "id": "xGZVfaNkRZuP"
      },
      "outputs": [],
      "source": [
        "def read_list_from_bin(input_path):\n",
        "    # Open the binary file in read mode\n",
        "    with open(input_path, 'rb') as bin_file:\n",
        "        # Deserialize and read the list from the binary file\n",
        "        data_list = pickle.load(bin_file)\n",
        "\n",
        "    return data_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "id": "suQBJ8o4QAbn"
      },
      "outputs": [],
      "source": [
        "#-------------------------Combining macro blocks-------------------------------------#\n",
        "def reconstruct_image(blocks, image_shape):\n",
        "    rows, cols = image_shape\n",
        "    block_size = blocks[0].shape[0]\n",
        "    reconstructed_image = np.zeros((rows, cols), dtype=np.float32)\n",
        "\n",
        "    block_index = 0\n",
        "    for row in range(0, rows, block_size):\n",
        "        for col in range(0, cols, block_size):\n",
        "            reconstructed_image[row:row+block_size, col:col+block_size] = blocks[block_index]\n",
        "            block_index += 1\n",
        "\n",
        "    return reconstructed_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "rqAZQBTkLqA3"
      },
      "outputs": [],
      "source": [
        "def create_video(images, output_video_path, fps=10):\n",
        "    # Get the height and width of the images\n",
        "    height, width, _ = images[0].shape\n",
        "\n",
        "    # Define the codec and create a video writer object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use 'XVID' for AVI format\n",
        "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Write each frame to the video file\n",
        "    for frame in images:\n",
        "        video_writer.write(frame)\n",
        "\n",
        "    # Release the video writer object\n",
        "    video_writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "y_rTdIVojI4u"
      },
      "outputs": [],
      "source": [
        "cnt=0\n",
        "n=0\n",
        "blockSize=16\n",
        "\n",
        "# Specify the folder to save the images\n",
        "output_folder = '/content/Processed_frames_8'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for img in images:\n",
        "  # print(\"1\")\n",
        "  if cnt%5==0:\n",
        "    # print(\"2\")\n",
        "    anchorFrame, targetFrame = preprocess(img, img, blockSize) #processes frame\n",
        "    img_I=img\n",
        "    # print(\"3\")\n",
        "    output_file_path=os.path.join(output_folder, f'frame_{cnt:04d}.jpg')\n",
        "    cv2.imwrite(output_file_path, anchorFrame)\n",
        "  else:\n",
        "    # print(\"4\")\n",
        "    anchorFrame, targetFrame = preprocess(img_I, img, blockSize) #processes frame\n",
        "    predictedFrame = blockSearchBody(anchorFrame, targetFrame, blockSize)\n",
        "    img_R = getResidual(anchorFrame, predictedFrame)\n",
        "    # print(\"5\")\n",
        "    output_file_path=os.path.join(output_folder,f'frame_{cnt:04d}.jpg')\n",
        "    cv2.imwrite(output_file_path, img_R)\n",
        "  cnt+=1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "91mrvbZkI5jv"
      },
      "outputs": [],
      "source": [
        "# Specify the folder to save the images\n",
        "output_folder = '/content/reconstructed_frames_8'\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "# output_file_path=os.path.join(output_folder,f'frame_{n:04d}.jpg')\n",
        "# cv2.imwrite(output_file_path, img_R)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "TB3yyQ5151KW"
      },
      "outputs": [],
      "source": [
        "jpg_folder_path='/content/Processed_frames_8'\n",
        "frms_processed = read_jpg_images(jpg_folder_path)\n",
        "\n",
        "# for frame in frms_processed:\n",
        "  # cv2_imshow(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "lI-4vTUS7Rdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac405637-af36-4d15-d938-a928264feff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Bits: 2227882\n",
            "PSNR: 29.504930635342703 dB\n",
            "Total Bits: 2208879\n",
            "PSNR: 29.261909193678264 dB\n",
            "Total Bits: 2210537\n",
            "PSNR: 29.078693915887786 dB\n",
            "Total Bits: 2209906\n",
            "PSNR: 29.186926179286473 dB\n",
            "Total Bits: 2209947\n",
            "PSNR: 29.21139093895025 dB\n",
            "Total Bits: 2228721\n",
            "PSNR: 29.477858779082247 dB\n",
            "Total Bits: 2206402\n",
            "PSNR: 29.59631319852771 dB\n",
            "Total Bits: 2208904\n",
            "PSNR: 29.367578169968354 dB\n",
            "Total Bits: 2210121\n",
            "PSNR: 29.16139644352491 dB\n",
            "Total Bits: 2209352\n",
            "PSNR: 29.174560307278945 dB\n",
            "Total Bits: 2227176\n",
            "PSNR: 29.79576666821382 dB\n",
            "Total Bits: 2206015\n",
            "PSNR: 29.735663614322462 dB\n",
            "Total Bits: 2208382\n",
            "PSNR: 29.505612679430243 dB\n",
            "Total Bits: 2209302\n",
            "PSNR: 29.326924879982176 dB\n",
            "Total Bits: 2209283\n",
            "PSNR: 29.35694988188327 dB\n",
            "Total Bits: 2228467\n",
            "PSNR: 29.606740594913738 dB\n",
            "Total Bits: 2208607\n",
            "PSNR: 29.35732429178654 dB\n",
            "Total Bits: 2210960\n",
            "PSNR: 29.18982420573205 dB\n",
            "Total Bits: 2210757\n",
            "PSNR: 29.291214709351458 dB\n",
            "Total Bits: 2211128\n",
            "PSNR: 29.228793276249174 dB\n",
            "Total Bits: 2230127\n",
            "PSNR: 29.281724508080124 dB\n",
            "Total Bits: 2209034\n",
            "PSNR: 29.127883425289088 dB\n",
            "Total Bits: 2210312\n",
            "PSNR: 29.078237681281074 dB\n",
            "Total Bits: 2210315\n",
            "PSNR: 29.152640692947077 dB\n",
            "Total Bits: 2210771\n",
            "PSNR: 29.11646793009207 dB\n",
            "Total Bits: 2232367\n",
            "PSNR: 29.137562679415932 dB\n",
            "Total Bits: 2208794\n",
            "PSNR: 29.150508984238122 dB\n",
            "Total Bits: 2209345\n",
            "PSNR: 29.154211433300205 dB\n",
            "Total Bits: 2208708\n",
            "PSNR: 29.348147372261565 dB\n",
            "Total Bits: 2208614\n",
            "PSNR: 29.416386363418997 dB\n",
            "Total Bits: 2228951\n",
            "PSNR: 29.425637787488704 dB\n",
            "Total Bits: 2206875\n",
            "PSNR: 29.518839575585147 dB\n",
            "Total Bits: 2208755\n",
            "PSNR: 29.286526249539975 dB\n",
            "Total Bits: 2207809\n",
            "PSNR: 29.503545960661786 dB\n",
            "Total Bits: 2208555\n",
            "PSNR: 29.465622718277512 dB\n",
            "Total Bits: 2231358\n",
            "PSNR: 29.26758824372763 dB\n",
            "Total Bits: 2208079\n",
            "PSNR: 29.233704678690327 dB\n",
            "Total Bits: 2209273\n",
            "PSNR: 29.218756811020633 dB\n",
            "Total Bits: 2208849\n",
            "PSNR: 29.33699210900525 dB\n",
            "Total Bits: 2209076\n",
            "PSNR: 29.324985507160164 dB\n",
            "Total Bits: 2229379\n",
            "PSNR: 29.528390707584688 dB\n",
            "Total Bits: 2206572\n",
            "PSNR: 29.634541967690026 dB\n",
            "Total Bits: 2207652\n",
            "PSNR: 29.46342542401044 dB\n",
            "Total Bits: 2208150\n",
            "PSNR: 29.44680564515442 dB\n",
            "Total Bits: 2209121\n",
            "PSNR: 29.32572406831266 dB\n",
            "Total Bits: 2231077\n",
            "PSNR: 29.33856227366837 dB\n",
            "Total Bits: 2206670\n",
            "PSNR: 29.689428493846798 dB\n",
            "Total Bits: 2208224\n",
            "PSNR: 29.39509502836312 dB\n",
            "Total Bits: 2208566\n",
            "PSNR: 29.334044935090972 dB\n",
            "Total Bits: 2209358\n",
            "PSNR: 29.286887286094792 dB\n",
            "Total Bits: 2232750\n",
            "PSNR: 29.30941643193076 dB\n",
            "Total Bits: 2207425\n",
            "PSNR: 29.523991299053804 dB\n",
            "Total Bits: 2208886\n",
            "PSNR: 29.468271489311665 dB\n",
            "Total Bits: 2209182\n",
            "PSNR: 29.376159329601666 dB\n",
            "Total Bits: 2209565\n",
            "PSNR: 29.28898967709673 dB\n",
            "Total Bits: 2232837\n",
            "PSNR: 29.174658063167485 dB\n",
            "Total Bits: 2207000\n",
            "PSNR: 29.392105515822063 dB\n",
            "Total Bits: 2209147\n",
            "PSNR: 29.259675917582936 dB\n",
            "Total Bits: 2209720\n",
            "PSNR: 29.090456737808815 dB\n",
            "Total Bits: 2209739\n",
            "PSNR: 29.207025120469872 dB\n",
            "Total Bits: 2234786\n",
            "PSNR: 29.168674150591535 dB\n",
            "Total Bits: 2206218\n",
            "PSNR: 29.635384761861108 dB\n",
            "Total Bits: 2209811\n",
            "PSNR: 29.112547022007682 dB\n",
            "Total Bits: 2212282\n",
            "PSNR: 28.952000575564266 dB\n",
            "Total Bits: 2211471\n",
            "PSNR: 28.990231627053376 dB\n",
            "Total Bits: 2234342\n",
            "PSNR: 29.13661107503939 dB\n",
            "Total Bits: 2206260\n",
            "PSNR: 29.60442050749897 dB\n",
            "Total Bits: 2210184\n",
            "PSNR: 29.160789047995145 dB\n",
            "Total Bits: 2210386\n",
            "PSNR: 29.13930476420417 dB\n",
            "Total Bits: 2211705\n",
            "PSNR: 28.975495632845888 dB\n",
            "Total Bits: 2235112\n",
            "PSNR: 29.14537513335854 dB\n",
            "Total Bits: 2209468\n",
            "PSNR: 29.238649009338687 dB\n",
            "Total Bits: 2209484\n",
            "PSNR: 29.303687666160094 dB\n",
            "Total Bits: 2211792\n",
            "PSNR: 29.052455829512486 dB\n",
            "Total Bits: 2212302\n",
            "PSNR: 29.06864272576545 dB\n",
            "Total Bits: 2234448\n",
            "PSNR: 29.177823677755292 dB\n",
            "Total Bits: 2208263\n",
            "PSNR: 29.323007759064097 dB\n",
            "Total Bits: 2212028\n",
            "PSNR: 28.892906299419288 dB\n",
            "Total Bits: 2214268\n",
            "PSNR: 28.691925884226485 dB\n",
            "Total Bits: 2215787\n",
            "PSNR: 28.606318205329686 dB\n",
            "Total Bits: 2235251\n",
            "PSNR: 29.166818459387844 dB\n",
            "Total Bits: 2210461\n",
            "PSNR: 29.084768420708723 dB\n",
            "Total Bits: 2211992\n",
            "PSNR: 28.962078801200526 dB\n",
            "Total Bits: 2212712\n",
            "PSNR: 28.978745259033598 dB\n",
            "Total Bits: 2213125\n",
            "PSNR: 28.79011207544771 dB\n",
            "Total Bits: 2230648\n",
            "PSNR: 29.485112719555985 dB\n",
            "Total Bits: 2209564\n",
            "PSNR: 29.238110240422564 dB\n",
            "Total Bits: 2211288\n",
            "PSNR: 29.12264799737697 dB\n",
            "Total Bits: 2211215\n",
            "PSNR: 29.198832006845088 dB\n",
            "Total Bits: 2211302\n",
            "PSNR: 29.15126246519992 dB\n",
            "Total Bits: 2232540\n",
            "PSNR: 29.33869529781646 dB\n",
            "Total Bits: 2209754\n",
            "PSNR: 29.156460769844166 dB\n",
            "Total Bits: 2212362\n",
            "PSNR: 28.963902408845357 dB\n",
            "Total Bits: 2212141\n",
            "PSNR: 29.10687700841729 dB\n",
            "Total Bits: 2212453\n",
            "PSNR: 29.025019064484994 dB\n",
            "Total Bits: 2231573\n",
            "PSNR: 29.415839342826008 dB\n",
            "Total Bits: 2210961\n",
            "PSNR: 29.045040488988086 dB\n",
            "Total Bits: 2210637\n",
            "PSNR: 29.16238668876233 dB\n",
            "Total Bits: 2211276\n",
            "PSNR: 29.053371140215237 dB\n",
            "Total Bits: 2212042\n",
            "PSNR: 29.04657032952704 dB\n",
            "Total Bits: 2231776\n",
            "PSNR: 29.356790811389445 dB\n",
            "Total Bits: 2211529\n",
            "PSNR: 28.915572847904002 dB\n",
            "Total Bits: 2212355\n",
            "PSNR: 28.843457826689487 dB\n",
            "Total Bits: 2212281\n",
            "PSNR: 28.933648463587268 dB\n",
            "Total Bits: 2213261\n",
            "PSNR: 28.824849396275923 dB\n",
            "Total Bits: 2229036\n",
            "PSNR: 29.568446042111223 dB\n",
            "Total Bits: 2209823\n",
            "PSNR: 29.149037600816143 dB\n"
          ]
        }
      ],
      "source": [
        "n=0\n",
        "frm_I=[]\n",
        "for frame in frms_processed:\n",
        "  gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  original_im_shape=gray_image.shape\n",
        "  # cv2_imshow(gray_image)\n",
        "  # print(original_im_shape)\n",
        "\n",
        "  dct_result = cv2.dct(np.float32(gray_image))\n",
        "  blocks = split_into_blocks(dct_result, block_size=8)\n",
        "\n",
        "  quantized_dct_high, quality_level_high = quantize(blocks, 100)\n",
        "  # print(quantized_dct_high[0:2])\n",
        "\n",
        "  input_arr=quantized_dct_high\n",
        "  # Calculate frequencies\n",
        "  frequencies = calculate_frequencies(input_arr)\n",
        "  # Build Huffman tree\n",
        "  huffman_tree = build_huffman_tree(frequencies)\n",
        "  # Generate Huffman code\n",
        "  huffman_code = generate_huffman_code(huffman_tree)\n",
        "  # Huffman encode the input array\n",
        "  encoded_arr = huffman_encode(input_arr, huffman_code)\n",
        "  # # Huffman decode the encoded array\n",
        "  # decoded_arr = huffman_decode(encoded_arr, huffman_code)\n",
        "\n",
        "  # Display the results\n",
        "  # print(\"Huffman Code:\", huffman_code)\n",
        "  # print(\"Encoded Array:\", encoded_arr[0:8])\n",
        "  # print(type(encoded_arr[0]))\n",
        "  # # print(\"Decoded Array:\", decoded_arr)\n",
        "  # print(huffman_code)\n",
        "\n",
        "  # Calculate total bits for the encoded array\n",
        "  total_bits = calculate_total_bits(encoded_arr)\n",
        "  # Display the result\n",
        "  print(\"Total Bits:\", total_bits)\n",
        "  # file_size=total_bits/1024\n",
        "  # print(file_size,\"kB\")\n",
        "\n",
        "  output_file_path = 'encoded_data.txt'\n",
        "  write_encoded_data_to_file(encoded_arr, output_file_path)\n",
        "  bin_file_path = 'my_list.bin'\n",
        "\n",
        "  # Write the list to a binary file\n",
        "  write_list_to_bin(encoded_arr, bin_file_path)\n",
        "\n",
        "  # # Read the list from the binary file\n",
        "  # read_list = read_list_from_bin(bin_file_path)\n",
        "\n",
        "  # print(\"Original List:\", my_list)\n",
        "  # print(\"Read List:\", read_list)\n",
        "\n",
        "  #------------------------Reconstruction-------------------#\n",
        "\n",
        "   # Read the list from the binary file\n",
        "  read_list = read_list_from_bin(bin_file_path)\n",
        "\n",
        "  decoded_arr = huffman_decode(read_list  , huffman_code)\n",
        "  # print(decoded_arr)\n",
        "\n",
        "  dequantized_blocks=[]\n",
        "  for blocks in decoded_arr:\n",
        "      # Filter out None values\n",
        "    filtered_array = np.where(blocks != None, blocks, np.nan)\n",
        "\n",
        "    # Convert the filtered array to a numeric type (float)\n",
        "    filtered_array = filtered_array.astype(np.float32)\n",
        "    dequantized_block=dequantize(filtered_array, 100)\n",
        "    dequantized_blocks.append(dequantized_block)\n",
        "  # print(dequantized_blocks[0:2])\n",
        "\n",
        "  merged_img=reconstruct_image(dequantized_blocks, original_im_shape)\n",
        "\n",
        "  inverse_dct_result = cv2.idct(np.float32(merged_img))\n",
        "  # print(inverse_dct_result[0:3])\n",
        "\n",
        "  # cv2_imshow(inverse_dct_result)\n",
        "\n",
        "  if n%5==0:\n",
        "    frm_I=inverse_dct_result\n",
        "    output_file_path=os.path.join(output_folder,f'frame_{n:04d}.jpg')\n",
        "    cv2.imwrite(output_file_path, frm_I)\n",
        "  else:\n",
        "    residualFrame=inverse_dct_result\n",
        "    reconstructTargetFrame = getReconstructTarget(residualFrame, frm_I)\n",
        "    output_file_path=os.path.join(output_folder,f'frame_{n:04d}.jpg')\n",
        "    cv2.imwrite(output_file_path, reconstructTargetFrame)\n",
        "  n+=1\n",
        "  psnr_value = psnr(gray_image, inverse_dct_result)\n",
        "  print(f\"PSNR: {psnr_value} dB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "FP2o-cXcL36_"
      },
      "outputs": [],
      "source": [
        "jpg_folder_path = '/content/reconstructed_frames_8'\n",
        "output_video_path = '/content/output.mp4'\n",
        "\n",
        "jpg_images = read_jpg_images(jpg_folder_path)\n",
        "\n",
        "# Create a video from the images\n",
        "create_video(jpg_images, output_video_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}